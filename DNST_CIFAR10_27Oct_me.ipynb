{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNST_CIFAR10_27Oct.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ami190/Densenet_CIFAR/blob/master/DNST_CIFAR10_27Oct_me.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SGIdMpjUCAmS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Problem Statement:<br>\n",
        "Image Classification for CIFAR 10 data using **Densenet Connected Convolution Network.**<br>\n",
        "Constarins:<br>\n",
        "1. You MUST use SGD.<br>\n",
        "2. You MUST perform image augmentation (and recommended you read Session 3 docs again).<br>\n",
        "3. You need to get a Validation Score of +92%<br>\n",
        "4. You cannot use more than 250 Epochs<br>\n",
        "5. You cannot have more than 1M parameters<br>\n",
        "6. Assignment default weightage is 100 pts (if you bead 92% target). For each 0.1% improvement, you get 1 point (i.e. 94% = 120 pts). <br>\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "cirxk3TICAmW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Solution:\n",
        "1. Using SGD with base learning rate of .10 and cyclic learning rate of .10 ,.01, .001 <br>\n",
        "2. Data preprocessing / Augmentation is done using Kears library ImageDataGenerator<br>\n",
        "3. Number of Parameters are  925,672.\n",
        "4. Validation Accuracy is 93.00"
      ]
    },
    {
      "metadata": {
        "id": "wEReknqACAma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing Dependencies \n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from  PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras import backend as k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QUP6cFHwCAml",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  1. Data Visualization"
      ]
    },
    {
      "metadata": {
        "id": "i-hmffFWCAmo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data() # loading data from CIFAR10\n",
        "\n",
        "single_img = x_train[45]\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "\n",
        "def visualize_images(x_train, y_train, classes, samples_per_class=10):\n",
        "    \"\"\"visualize images from training data \"\"\"\n",
        "    num_classes = len(classes)\n",
        "    for y, cls in enumerate(classes):\n",
        "        idxs = np.flatnonzero(y_train == y) # get all the indexes of cls\n",
        "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "        for i, idx in enumerate(idxs): # plot the image one by one\n",
        "            plt_idx = i * num_classes + y + 1 # i*num_classes and y+1 determine the row and column respectively\n",
        "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "            plt.imshow(x_train[idx].astype('uint8'))\n",
        "            plt.axis('off')\n",
        "            if i == 0:\n",
        "                plt.title(cls)\n",
        "    plt.show()\n",
        "\n",
        "visualize_images(x_train,y_train,classes)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BOsBZR_2CAmy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2. Data Preprocessing :\n",
        "Data preprocessing is a data mining technique that involves transforming raw data into an understandable format. Real-world data is often incomplete, inconsistent, and/or lacking in certain behaviors or trends, and is likely to contain many errors. Data preprocessing is a proven method of resolving such issues\n",
        "\n",
        "Using Kears inbulid library for Image augmentation , ImageDataGenerator.\n",
        "\n",
        "##### ImageDataGenerator class :\n",
        "Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches).\n",
        "\n",
        "These images are not HD, rather small, Dataset contains 50000 training and 10000 testing images of 10 different classes.\n",
        "Using image augumentaion to crop widthwise and heightwise so that tiney features are learned. As the images are not digits, It is vital for network to learn mirror images as well."
      ]
    },
    {
      "metadata": {
        "id": "11MLlaixCAm0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Image Augmentation using Kears inbulit lib Image Data Generator\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40, #degree of random rotations of image\n",
        "        width_shift_range=0.2, #this will crop the image widthwise by moving width fraction of total width, if < 1\n",
        "        height_shift_range=0.2, #this will crop the image heighteise by Moving height fraction of total height, if < 1\n",
        "        zoom_range=0.05, # to learn more features zooming image\n",
        "        channel_shift_range=0.1,#Random Channel Shift\n",
        "        fill_mode='nearest', # points outside the boundaries are filled according to the\n",
        "        horizontal_flip=True # mirror image\n",
        ")\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hw9mw3y7CAnC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Number of data sampels \n",
        "n_training = len(x_train)\n",
        "n_testing = len(x_test)\n",
        "print('Loaded CIFAR10 database with {} training and {} testing samples'.format(n_training, n_testing))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6iY4HN5zCAnK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5D4iBAMCAnP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64 # number of batches per epoch \n",
        "num_classes = 10 #number of classifictions \n",
        "epochs = 50 #number of times each image is scanned \n",
        "l = 10 # growth rate of network\n",
        "num_filter = 24 # number of filters \n",
        "compression = 0.9\n",
        "#dropout_rate = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JMRQP5GhCAnT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing ZZ\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AmMrnwgjCAnZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.Design Dense Neural Convolution Network:\n",
        "Idea behind dense network is that many features are lost in sequential network moving from first layer to last. In Dense network is that every layer is connected to all its previous layers and its succeeding ones, thus forming a **Dense Block.**\n",
        "\n",
        "Densenet targts solution for *Vanishing -gradient*, *strengthen feature propagation* , *encourage feature reuse*, and *substantially reduce the number of parameters*.\n",
        "\n",
        "Densely connected layers process can easy explode the neural network parameters. It is vital to impliment Compression, dropout and pooling to be able to reduce cost.\n",
        "\n",
        "Some critcal factors in Dense Neural Nets:\n",
        "1. Dense Layers are concatenated with each other not added.\n",
        "2. These layes have to of same height and width.\n",
        "3. add_transition fuction uses  Batchnorm Relu compression to make layers pass to next block\n",
        "4. Growth rate(l) decides the depth of the network.\n",
        "5. num_filter are number of channels or kernals."
      ]
    },
    {
      "metadata": {
        "id": "IeRMWtU0CAnZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter, dropout_rate):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W5RFScY7CAne",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter, dropout_rate):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "        Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PdevdT_5CAni",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sjJyzuWGCAnk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_filter = 24\n",
        "dropout_rate = 0.0 #as images are small its critical to learn all features.\n",
        "l = 10\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5rEO4Z1OCAno",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HM7eszysCAnq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "# learning rate are updated as per number of epocs\n",
        "def lr_schedule(epoch):\n",
        "    lrate = 0.10\n",
        "    if epoch > 75:\n",
        "        lrate = 0.001\n",
        "    elif epoch > 100:\n",
        "        lrate = 0.0001       \n",
        "    return lrate\n",
        " \n",
        "sgd = keras.optimizers.SGD(lr=0.10,momentum = 0.0, decay = 0.0 , nesterov = False)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eB6UiAzNCAnt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# To save model weights for best accuracy model used callbacks and check points \n",
        "filepath=\"weight_final_27oct.hdf5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint,LearningRateScheduler(lr_schedule)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "VaK-ejHcCAnw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model fit_generator  train the model on aumented images.\n",
        "#here one main point to consider in steps_per_epoch (after aug. dataset increses so its wise to go thru random images more times)\n",
        "model.fit_generator(datagen.flow(x_train, y_train,batch_size=64),steps_per_epoch=2*x_train.shape[0] // batch_size,epochs=50,validation_data=(x_test, y_test),callbacks=callbacks_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "_f4Nc361CAnz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# connection disconnected so loading the model from saved weights.\n",
        "model.fit_generator(datagen.flow(x_train, y_train,batch_size=64),steps_per_epoch=2*x_train.shape[0] // batch_size,epochs=20,validation_data=(x_test, y_test),callbacks=callbacks_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQNlcduOCAn4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# connection disconnected so loading the model from saved weights.\n",
        "model.load_weights(\"weight_final_27oct.hdf5\")\n",
        "model.fit_generator(datagen.flow(x_train, y_train,batch_size=64),steps_per_epoch=2*x_train.shape[0] // batch_size,epochs=10,validation_data=(x_test, y_test),callbacks=callbacks_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q2U7X23FCAn9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**ReduceLROnPlateau** is used to improve LR when model has stop improving. Model benefits from reducing the LR and learn more slowly."
      ]
    },
    {
      "metadata": {
        "id": "m25Ylw6lCAn9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='auto', min_delta=0.0001)\n",
        "\n",
        "callbacks_list = [checkpoint,reduce_lr]\n",
        "model.fit(x_train, y_train,batch_size=64,epochs=50,validation_data=(x_test, y_test),callbacks=callbacks_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cyOEiZpoCAoA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks_list = [checkpoint]\n",
        "model.fit(x_train, y_train,batch_size=64,epochs=20,validation_data=(x_test, y_test),callbacks=callbacks_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VIX0fqfCAoE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9n1QDYCACAoH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_models_Final.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jAZADxp1CAoL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}